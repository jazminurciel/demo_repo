{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from flask import abort, Flask, jsonify, request\n",
    "from symspellpy.symspellpy import SymSpell, Verbosity\n",
    "from time import time\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import spacy\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\bq\\b|\\bk\\b', 'que', text) # replace q or x with que\n",
    "    text = re.sub(r'\\bd\\b', 'de', text) # replace d with de\n",
    "    text = re.sub(r'\\bx\\b', 'por', text) # replace x with por\n",
    "    text = re.sub(r'\\btmb\\b', 'también', text) # replace tmb with tambien\n",
    "\n",
    "    duplicates = re.compile(r'([^(c,l,n,r)L0])\\1{1,}')\n",
    "    double_clnr = re.compile(r\"(.)\\1{2,}\")\n",
    "    while duplicates.search(text)!=None:\n",
    "        text = text.replace(duplicates.search(text).group(),duplicates.search(text).group()[0]) #remove multiple letters\n",
    "    text = double_clnr.sub(r\"\\1\\1\", text) #except double c, l, n, and r\n",
    "\n",
    "    text = re.sub(r'([ja]{5,}|[je]{5,}|[ji]{5,}|[ha]{5,}|[he]{5,})', 'jaja', text)  # remove dirty laughs\n",
    "\n",
    "    text = re.sub(r'(\\.|,|:|;|!|\\?|\\[|\\]|\\(|\\))', ' ', text)  # replace simbols between words with spaces\n",
    "    text = re.sub(r'\\d+', '', text) #remove numbers\n",
    "\n",
    "    text = re.sub(r'[%s]' % re.escape(\"\"\"¿¡!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~…\"\"\"), '', text)  # remove punctuations\n",
    "    text = re.sub(r'\\b[^aeyou]\\b', ' ', text) # remove single char\n",
    "    text = re.sub('\\s+', ' ', text)  # remove extra whitespace\n",
    "\n",
    "    text = text.encode('latin', 'ignore').decode('latin')\n",
    "\n",
    "    max_edit_distance_lookup = 3\n",
    "    text = sym_spell.lookup_compound(text,max_edit_distance_lookup)[0].term\n",
    "\n",
    "    tokens= nlp(u\"\"+text)\n",
    "    new_text= ' '.join([t.lemma_ for t in tokens])\n",
    "\n",
    "    return [new_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "\n",
    "sym_spell = SymSpell(\n",
    "    max_dictionary_edit_distance=3,\n",
    "    prefix_length=7,\n",
    "    count_threshold=1,\n",
    "    compact_level=5,\n",
    ")\n",
    "\n",
    "sym_spell.load_dictionary(corpus='resources/es_real_freq_full.txt',term_index=0,count_index=1,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0717 11:38:37.048037  6532 deprecation_wrapper.py:119] From C:\\Users\\PREVENCION-1\\Anaconda3\\envs\\ml_service\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0717 11:38:37.592608  6532 deprecation_wrapper.py:119] From C:\\Users\\PREVENCION-1\\Anaconda3\\envs\\ml_service\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0717 11:38:37.691098  6532 deprecation_wrapper.py:119] From C:\\Users\\PREVENCION-1\\Anaconda3\\envs\\ml_service\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0717 11:38:38.456313  6532 deprecation_wrapper.py:119] From C:\\Users\\PREVENCION-1\\Anaconda3\\envs\\ml_service\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0717 11:38:38.469276  6532 deprecation.py:506] From C:\\Users\\PREVENCION-1\\Anaconda3\\envs\\ml_service\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0717 11:38:39.568248  6532 deprecation_wrapper.py:119] From C:\\Users\\PREVENCION-1\\Anaconda3\\envs\\ml_service\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0717 11:38:40.627077  6532 deprecation_wrapper.py:119] From C:\\Users\\PREVENCION-1\\Anaconda3\\envs\\ml_service\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0717 11:38:40.644032  6532 deprecation.py:323] From C:\\Users\\PREVENCION-1\\Anaconda3\\envs\\ml_service\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = load_model('NN_models/Embedding_LSTM-GRU_lemma.h5')\n",
    "tokenizer = pickle.load(open('models/tokenizer_embedding_lstm-gru.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 20, 100)           1200000   \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 20, 192)           225024    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 20, 32)            26752     \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 64)                18624     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,470,465\n",
      "Trainable params: 1,470,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input text: Que no debo imaginarme cosas negativas. Debo pensar positivo y creer que mi esposo me ama\n",
      "\n",
      "Text after preprocessing: que no deber imaginarme coser negativo deber pensar positivo y creer que mi esposar me amar\n",
      "\n",
      "Score 0.2734161913394928\n",
      "Event: Sentiment_N\n",
      "\n",
      "Process took 6.668175935745239 seconds to finish\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_len=20\n",
    "\n",
    "text = \"\"\"Que no debo imaginarme cosas negativas. Debo pensar positivo y creer que mi esposo me ama\n",
    "\"\"\"\n",
    "\n",
    "start = time()\n",
    "print(f\"\\nInput text: {text}\")\n",
    "clean = clean_text(text)\n",
    "print(f\"Text after preprocessing: {clean[0]}\\n\")\n",
    "text_tokens = tokenizer.texts_to_sequences(clean)\n",
    "text_pad = pad_sequences(text_tokens,maxlen=max_len)\n",
    "score = model.predict(text_pad)[0][0]\n",
    "print(f\"Score {score}\")\n",
    "event = (\"Sentiment_P+\"if score>=0.8 else\n",
    "         \"Sentiment_P\" if 0.60<=score<0.8 else\n",
    "         \"Sentiment_NEU\" if 0.40<=score<0.60 else\n",
    "         \"Sentiment_N\" if 0.20<=score<0.40 else\n",
    "         \"Sentiment_N+\")\n",
    "print(f\"Event: {event}\")\n",
    "print(f\"\\nProcess took {time()-start} seconds to finish\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_service]",
   "language": "python",
   "name": "conda-env-ml_service-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
